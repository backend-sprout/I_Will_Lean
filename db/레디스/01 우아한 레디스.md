# 우아한 레디스  

**다루지 않는 내용**   
* Redis Persistence(RDB, AOF). 
* Redis Pub/Sub 
* Redis Stream 
* 확률적 자료구조 
    * Hyperloglog
* Redis Module  

# 레디스 간략 소개   

* In-Memory Data Structure Store.  
* Open Source(BSD 3 License - 수정 가능)    
* Support data structures.  
    * Strings, set, sorted-set, hashes, list
    * Hyperloglog, bitmap, geospatial index 
    * Stream
* Only 1 Committer 

## 캐시 

* 나중에 사용될 요청의 결과를 미리 저장해두었다가 빠르게 서비스를 해주는 것을 의미   

**CPU CACHE**   
* Disk
* Memory 
* L3 Cache 
* L2 Cache
* L1 Cache
* Core 

**파레토 법칙**    
* 우리 사회에 일어나는 현상은 80:20 으로 이루어진다.   
* 전체 요청의 80%는 20%의 사용자가 활용 -> 캐싱 전략 사용하자   

### Cache 구조
#### Look aside Cache 

1. webServer는 데이터가 존재하는지 Cache 에 먼저 확인한다.     
2. Cache에 데이터가 있으면 Cache에서 데이터를 가져온다.      
3. Cache에 데이터가 없으면 DB에서 데이터를 가져온다.   
4. DB에서 불러온 데이터를 Cache에 다시 저장한다.   

일반적으로 제일 많이 사용하는 패턴이다.     
쓰기가 적고 읽기가 많을 때 주로 사용한다.   

#### Write Back 

1. WebServer는 모든 데이터를 Cache에만 저장한다.     
2. Cache에 특정 시간동안의 데이터가 저장된다.      
3. Cache에 있는 데이터를 DB에 저장한다.      
4. DB에 저장된 데이터를 삭제한다.    
    
인메모리가 읽기는 물론 쓰기도 빠르다.        
쓰기가 빈번한 경우, 배치 형식으로 레디스에 저장해두었다가 DB에 저장하는 방식이다.        
**단, 단점으로 메모리기에 리프팅되면 날라가게 되므로 데이터가 사라질 가능성이 있다.**      

WriteBack은 주로 로그를 DB에 저장할 때 사용한다.(한번에 밀어났다가 일정 주기별로 한번에 보낸다)     
또는 극단적으로 헤비한 Write가 있다면 사용한다.   

## Redis 사용처 

* Remote Data Server 
    * A서버, B서버, C서버에서 데이터를 공유하고 싶을 때,    
* 한대에서만 필요하다면, 전역 변수를 쓰면 되지 않을까?     
    * Redis 자체가 Atomic을 보장해준다(싱글 스레드라)  
* 주로 많이 쓰이는 곳  
    * 인증 토큰을 저장(Stirngs 또는 hash). 
    * Ranking 보드를 사용(SortedSet) 
    * 유저 API Limit
    * 잡큐(List) 


# Redis Collections 
##  왜 Collection이 중요한가
  
memCached는 Collection을 제공하지 않는다.       
레디스는 Collection을 제공해줌으로써 이로 인한 개발의 편의성과 난이도가 달라진다.          
 
**랭킹 서버**     
* 서버가 여러대인데 싱크 맞추는데 어려움이 있다.    
* 가장 간단한 방법 
    * DB에 유저의 Score 저장하고 Score로 Order by로 정렬 후 읽기 
    * 개수가 많아지면 속도에 문제가 발생할 수 있다.     
        * 결국 디스크를 사용하므로  

* In-Memory 기준으로 랭킹 서버의 구현이 필요한데   
* Redis의 sorted Set을 이용하면 랭킹을 구현할 수 있다.   
    * 덤으로 Replication 도 가능하다.   
    * 다만 가져다 쓰면 거기의 한계에 종속적이게 된다.   
        * 랭킹에 저장해야할 id가 1개당 100Byte라고 했을 대   
            * 10명 1K
            * 10000명 1M
            * 10000000명 1G
            * 10000000000명 1TB
   
**친구 리스트**   
* 친구 리스트를 Key/Value 형태로 저장한다면?    
* 현재 유저 123의 친구 key는 friends:123, 현재 친구 A가 있는 중  
    * 트랜잭션1
        * 친구 리스트 friends:123을 읽는다.  
        * friends:123의 끝에 친구 B를 추가한다.   
        * 해당 값을 frend:123에 저장한다.  
    * 트랜잭션2 
        * 친구 리스트 friends:123을 읽는다  
        * friends:123의 끝에 친구 C를 추가한다.   
        * 해당 값을 frineds:123에 저장한다.  

* 동시성 문제가 발생하면 아래와 같다.  
    * AB
    * AC
* Redis의 경우는 자료구조가 Atomic 하기 때문에 RaceCondition을 피할 수 있다.     
* 그래도 잘못짜면 발생한다.(클릭을 빠르게 2번하면 중복 데이터 발생)       
   
외부의 Collection을 잘이용하는 것으로,    
여러가지 개발 시간을 단축시키고ㅡ 문제를 줄여줄 수 있기 때문에 Collection이 중요하다.    

## Redis Collections 

* Strings
* List
* Set
* SortedSet(Score를 통해 순서를 줄 수 있다) 
* Hash

### Strings

* set key value
* get key
* set token:1234567 abcdefghijk
* get token:1234567

여기서 중요한건 명령어가 아닌 key이다.    
1234567와 같은 prefix를 주면 식별자로 여러 방면으로 사용할 수 있다.   
 
* mset key value key value 한번에 여러개 저장
* mget key key key 

### List

* Lpush key A
    * key:(A) 
* Rpush key B
    * key:(A ,B)
* Lpush key C
    * key:(C, A ,B)
* Rpush key DA
    * key:(C, A ,B, D, A)

잡큐는 리스트를 많이 쓴다.   
  
  * LPOP : 왼쪽에서 꺼내기 
  * RPOP : 오른쪽에서 꺼내기 
  * BLPOP : 데이터를 PUSH 하기 전까지 대기  

### Set 

* SADO key value : 벨류 추가 
* SMEMERS key : 모든 값 가져옴(추가하자)
* SISMEMBERS key value : value가 존재하면 1, 없으면 0
* 특정 유저를 Follow 하는 목록 저장시 사용 

### Sorted Set 

* ZADO key score value : score 기준으로 정렬(우선순위) 
* ZRANGE key startindex endindex : 해당 인덱스 범위값을 모두 가져온다.  
    * Zrange testkey 0~1
    * 모든 범위 가져옴 
* 유저 랭킹 보드로 사용할 수 있다.  
    * SoretedSets의 socre는 double 타입이기 때문에, 값이 정확하지 않을 수 있다.   
    * 데이터에서는 실수가 표현할 수 없는 정수값들이 존재한다.  
    * 자바스크립트 사용한다면 long 값은 String으로 보내는 것이 좋다.  
    * 의외로 생각보다 문제가 종종 발생 
        * 특정 유저의 글을 시간값으로 주고 오늘 부터 내일까지 가져오는데 빠질 수 있음
        * 어제꺼인데 들어올 수 있음 

**정렬이 필요한 값이 필요하다면?**     
* select * from rank order by score limit 50, 20; 
    * zrange rank 50 70
* select * from rank order by score desc limit 50 20;
    * Zrevrange rank 50 70 // 거꾸로 가져옴 

**Score 기준으로 뽑고 싶다면?**    
* select * from rank where score >= 70 and score < 100;
    * zrangebyscore rank 70 100 
* select * from rank where score > 70;
    * zrangebyscore rank (70 +inf
  
### Hash
> key 밑에 Sub key가 존재한다.    

**기본 사용법**    
* hashset key subkey1 value subkey2 value
* hagetall key 
    * 해당 key의 모든 서브키와 value를 가져옴   
* hget key 서브키 
* hmget ket 서브키1 서브키2 서브키3   

**간단한 SQL을 대체한다면**    
* insert into users(name, email) values('charsyam', 'kwj1270@naver.com');
* hmset charsyam name cahrsyam email kwj1270@naver.com

### Collection 주의 사항   
* 하나의 컬렉션에 너무 많은 아이템을 담으면 좋지 않음     
    * 10000개 이하 몇 천개 수준으로 유지하는게 좋음     
* Expire는 Collection의 item 개별로 걸리지 않고 전체 Collection에 대해서만 걸림      
    * 즉, Collection에 expire가 걸려있다면 아이템 모두 삭제        
    
# Redis 운영 

* 메모리 관리를 잘하자    
* O(N) 관련 명령어는 주의하자.  
* Replication 
* 권장 설정 Tip 

## 메모리 관리를 잘하자   
     
* Redis는 In-Memory Data Store      
* Physical Memory 이상을 사용하면 문제가 발생한다.          
    * Swap이 있다면 Swap 사용으로 해당 메모리 Page 접근마다 늦어진다.        
    * Swap이 없다면? -> OOM 터졌겠지      
* Maxmemory를 설정하더라도 이보다 더 사용할 가능성이 크다.
    * Redis가 아는 자기가 사용하는 메모리의 제한  
    * 특정 메모리 이상 사용하지 말라는 키워드, 랜덤 키 또는 expire 목록에서 삭제함
    * 레디스는 메모리 풀이 아닌 메모리 할당이랑 해제를 JMalloc 을 이용한다.   
    * 즉 메모리 얼로케이트에 의존하는데 이 구현에 따라서 성능이 왔다 갔다할 수 있음(메모리 지웠다지만 잡고 있을 수 있음)  
    * 메모리 페이지 사이즈가 4096 때, 1바이트 할당 요청하면 JMalloc은..? -> 4096을 가진다.(페이지 단위이므로)
    * 메모리 파편화가 발생할 가능성이 높다.  
* RSS값을 모니터링 해야함 (레디스가 실제 메모리를 사용하고 있는 메모리)     
    
**즉, 많은 업체가 현재 메모리를 사용해서 SWAP을 쓰고 있다느걸 모를때가 많다.**        
   
**메모리 관리**  
* 큰 메모리를 사용하는 instance 하나보다는 **작은 메모리를 사용하는 instance 여러개가 안전하다.**        
* Redis는 필연적으로 Fork를 하게된다.   
* Read가 많은 서비스는 문제 없지만, Write가 해비한 레디스는 최대 메모리는 2배까지 사용할 수 있다.  
* CPU 4 Core, 32GB Memory       

**파편화**    
* Redis는 메모리 파편화가 발생할 수 있다.    
    * 4.x대부터 메모리 파편화를 줄이도록 jemlloc에 힌트를 주는 기능이 들어갔으나.      
    * jemalloc 버전에 따라서 다르게 동작할 수 있다.      
* 3.x대 버전   
    * 실제 user memory는 2GB로 보고가 되지만 11GB의 RSS를 사용하는 경우가 자주 발생     
* 다양한 사이즈를 가지는 데이터보다는 유사한 크기의 데이터를 분리하는 경우가 유리(클러스터..?)   
 
#### 메모리가 부족할 때는? 
 
* Cache is Cash!!!   
    * **좀 더 메모리 많은 장비로 Migration**      
    * 메모리가 빡빡하면 Migration 중에 문제가 발생할 수도...    
* 있는 데이터 줄이기    
    * **데이터를 일정 수준에서만 사용하도록 특정 데이터를 줄인다.**          
    * 다만 이미 Swap 을 사용중이라면, 프로세스를 재시작 해야함     
    * 클러스터 운영도 고민 

##### 메모리가 줄이기 위한 설정 
* 기본적으로 Collection 들은 다음과 같은 자료구조를 사용한다.   
    * Hash -> HashTable 하나 더 사옴   
    * SortedSet -> Skiplist와 HashTable을 이용   
    * Set -> HashTable  
    * **해당 자료구조들은 메모리를 많이 사용한다.**       
* 위 자료구조보다는 Ziplist를 이용하자.(몇십 몇백만 사용하면 속도는 줄지만 메모리는 절약)   
* 정확히 말하면, 기존 자료구조를 사용할 때, ZipList를 쓰도록 설정하는 것이다.   
  
##### Ziplist 구조     
* In-memory 특성상, 적은 개수라면 선형 탐색을 하더라도 빠르다.        
* List, hash, SortedSet. 등을 ZpiList로 대체해서 처리하는 설정이 존재      
    * 해시 : hash-max-ziplist-entries(몇개), hash-max-ziplist-value(얼마까지)    
    * 리스트 : list-max-zpilist-size(몇개), list-max-ziplist-value(얼마까지)   
    * 셋 : zset-max-ziplist-entries(몇개), zset-max-ziplist-value(얼마까지) 
* 많이 집어넣으면 원래 자료구조로 바뀌긴 한다.   
     
## O(N)관련 명령어는 주의하자.   
* Redissms Single Threaded. 
    * 그러면 Redis가 동시에 여러 개의 명령을 처리할 수 있을까? -> 없다. 
    * 참고로 단순한 get/set의 경우, 초당 10만 TPS 이상 가능(CPU속도에 영향을 받습니다)   
    * 만약 요청 하나당 Latency가 1초면 -> 펑  

### Redis is Single Tread 

<img width="611" alt="image" src="https://user-images.githubusercontent.com/50267433/159492414-17937efe-627c-4d50-bbdf-b18202522bb3.png">
 
* TCP 요청으로 Packet이 끊어서 오면       
* ProcessInputBuffer에서 특정 개수의 패킷들을 하나의 Command로 만든다.      
* Packe으로 하나의 Command가 완성되면 ProcessCommand에서 실제로 실행한다.    
* 실행되는 동안의 다른 패킷은 대기가 된다.   
* 즉, 루프를 탈출해야 다음 명령어를 실행하는 것이다.   
* 만약 Latency가 1초면 그만큼 지연시간이 배로 길어진다.   

### Single Thread 의미    
* 한번에 하나의 명령만 수행가능   
    * 그럼 긴 시간이 필요한 명령을 수행하면? -> 망함 
* KEYS 
* FLUSHALL, FLUSHDB
* Delete Collection
* Get All Collections 
* 위 명령어들은 사용하지 말자   

#### 대표적인 실수 사례   
* key가 백만개인데, 확인을 위해 keys 명령어를 사용하는 경우   
    * 모니터링 스크립트가 일초에 한번씩 keys를 호출하는 경우도,  
* 아이템이 몇 만개든 hash, sorted set, set에서 모든 데이터를 가져오는 경우 
* 예전의 Spring security oauth Redis Token Store.  

**keys는 어떻게 대체할 것인가?**   
* scan 명령을 사용하는 것으로 하나의 긴 명령을 짧은 여러번의 명령으로 바꿀 수 있다.     
* 스캔은 커서 방식이다(짧게 여러번 돌리는 형태)  
* 여러번 돌리는 그 텀 사이에 다른 명령어를 실행하기에 괜찮은 방식이다.    

**Collection의 모든 item을 가져와야할 때는?**   
* Collection의 일부만 가져오거나   
    * Sorted Set 
* 큰 Collection을 작은 여러개의 Collection으로 나눠서 저장 
   * userranks -> userrnak1, userrank2, userrank3  
   * 하나당 몇천개 안쪽으로 저장하는게 좋다.  

**Spring Security oauth RedisTokenStore 이슈**.   
* AccessToken 저장을 List(O(N)) 자료구조를 통해서 이루어졌음   
    * 검색 삭제시에 모든 item을 매번 찾아봐야 함  
    * 100만 개 쯤 되면 전체 성능에 영향을 줌 
    * 현재는 Set(O(1))을 이용해서 검색, 삭제를 하도록 수정되어 있음  

# Redis Replication 
* Async Replication(비동기 레플리케이션)   
    * Replication Lag이 발생할 수 있다.(비동기시에 데이터가 일치하지 않을 수 있다)         
* Replicaof(>= 5.0.0 버전) or slaveof 명령으로 설정 가능  
    * Replication `hostname port(마스터 주소)`  
* DBMS로 보면 statement replication가 유사   

## Replication 설정 과정  
* secondary에 replicaof or salveof 명령 전달   
* secondary는 primary에 sync 명령 전달   
* primary는 현재 메모리 상태를 저장하기 위해 
    * fork 
* fork한 프로세서(새로 생성된)는 현재 메모리 정보를 disk 에 dump. 
* 해당 정보를 secondary 에 전달 
* fork 이후의 데이터를 secondary에 계속 전달  
   
## Replication 시 주의할 점      
* Replication 과정에서 fork 가 발생하므로 메모리 부족이 발생할 수 있다.        
* redis-cli --rdb 명령은 현재 상태의 메모리 스냅샷을 가져오므로 같은 문제를 발생시킨다.   
* AWS나 클라우드의 Redis는 좀 다르게 구현되어서 좀더 해당 부분이 안정적이다.(포크없이 리플리케이션 전달)     
* 많은 대수의 Redis 서버가 Replica를 가지고 있다면    
    * 네트워크 이슈나, 사람의 작업으로 **동시에 replication이 재시도 되도록 하면 문제가 발생할 수 있음**    
    * ex) 같은 네트워크 안에서 30GB를 쓰는 redis Master 100대 정도가   
         리플리케이션을 동시에 재시작하면 어떤 일이 벌어질 수 있을가?     
         네트워크가 끊어지고 다시 연결되고 반복될거임  
         

## Redis.conf 권장 설정   

* Maxclient 설정 50000 
* RDB/AOF 설정 off
* 특정 commands disable 
    * keys
    * aws의 elasticcache는 이미 하고 있다.  
* 전체 장애의 90% 이상이 KEYS와 Save 설정을 사용해서 발생  
* 적절한 ziplist 설정   

# Redis 데이터 분산  


* 데이터의 특성에 따라서 선택할 수 있는 방법이 달라진다.   
    * cache 일 때는 유아한 redis
    * persistence 해야하면 안 우아한 redis
        * open the hell gate 

## Redis 데이터 분산 
* Application
    * Consistence Hashing
        * twmproxy 를 사용하는 방법으로 쉽게 사용가능 
    * Sharding 
* Redis Cluster      

### Consistent Hashing 

해시 방식으로 처리하다가 서버가 증설되면..?  또는 죽으면..?        
리밸런스를 할 수 있지만, 이는 좋은 현상이 아니다.(장애에 취약하다)   

서버 한대당 빠지거나 들어와도, 딱 `1/총개수`만 데이터를 변경하도록 하는 방식이다.   

* 10000
* 20000
* 30000 

서버가 각각의 해시값을 키값으로 가지고 있는다.     
어떤 값이 들어오면 자기보다 크고 가장 가까운 서버로 보내는 망식이다.   

* 1500 이면 -> 10000으로 보냄 
* 12000이면 -> 20000으로 보냄 
* 23500이면 -> 30000으로 보냄 
* 35000이면 -> 제일 큰게 없으니 처음으로 -> 10000으로 보냄 
* 45000이면 -> 제일 큰게 없으니 처음으로 -> 10000으로 보냄   

여기서 중간 서버를 뺀다면?    

* 23500인 사람만 30000으로 가고 나머지는 변동이 없다.   
* 즉, 삭제된 서버의 데이터만 이동시킨다.   
* 살아나는 것도 마찬가지이다.   

### 샤딩  

* 데이터를 어떻게 나눌 것인가 == 데이터를 어떻게 찾을 것인가      
* 하나의 데이터를 모든 서버에서 찾아야 한다면? -> 모든 서버에 부하 주는 일이다 -> 하나의 서버에서 바로 접근하도록 


#### Range 
* 그냥 특정 Range를 정의하고 해당 Range에 속하면 거기에 저장   
    * 이벤트 같은 특정 상황에 데이터가 몰려 불균형이 발생할 수 있다.  

Range는 서버의 상황에 따라서 놀고 있는 서버와 안놀고 있는 서버와 극심하게 나뉜다.      
그런데 놀고 있는 서버가 있다고 해서, 바꿀수 있냐? -> 안되는게 단점이다.       
단, 확장에 있어서는 서버를 하나 더 늘리면 되니까 편하다.     
또, 파레토 법칙에 의해 초기 사용자들이 80퍼의 이용을 하는데 초기 서버만 열일 하는 문제가 발생한다.   

#### 모듈러(해시)   

모듈러는 2의 배수로 증가시키는 것이 좋다.       
규칙성은, 2배하면 -> 자기가 이동할 서버가 바로 결정된다.(2배수의 모듈러로)    

**2배 증기**
* 0 -> 2
* 1 -> 3

**2배 더 증기**
* 0 -> 4
* 1 -> 5 
* 2 -> 6
* 3 -> 7

각 서버의 절반이 다음 서버로 넘어간다.   
단, 2배씩 늘어나는 것이기에 서버의 증가률이 너무 많다.       
index 서버를 따로 두고 특정 키는 어느 서버로 가는지 알려줄 수 있는 방법이 있다.  
(인덱스 서버가 죽으면 이동 불가능 -> 다른 장애 포인트 생긴것임)   

# Redis Cluster 
 
* Hash 기반으로 Slot 16384 로 구분
    * hash 알고리즘은 CRC16을 사용 
    * Slot = crc16(key) % 16384
    * key가 key(hashKey)패턴이면 실제 crc16에 hashkey가 사용된다.   
    * 특정 Redis 서버는 이 slot range를 가지고 있고,   
      데이터 migration은 이 slot 단위의 데이터를 다른 서버로 전달하게 된다.(migrate command 이용)   
    * 즉, Slot range 를 가지고 있다. 물론 자동으로 안되기 때문에 관리자가 샤딩을 설정해줘야함.
    * 각 마스터(Primary) 는 슬레이브(Secondary)를 가지고 있고 만약 Primary 가 죽으면 Secondary 가 Primary 로 승격된다.
      
각 마스터에는 Slot range 가 있어서 클라이언트가      
slot 범위를 벗어난 키를 요청하면 에러와 함께 해당 슬롯의 마스터를 리턴한다.      
이때 클라이언트가 해당 슬롯 마스터로 다시 요청해야한다.       
그러므로 라이브러리에 의존적이다.(다시 요청해야 하므로)   
  
**장점**   
* 자체적인 마스터, 슬레이브 Failover.  
* Slot 단위 데이터 관리.  
  
**단점**  
* 메모리 사용량이 더 많음    
* Migration 자체는 관리자가 시점을 결정해야한다.  
* 라이브러리 의존적.   

# Redis Failover 

* coordinator 기반 Failover 
* vip/dns 기반 failover 
* redis cluster의 사용 

## coordinator 기반 Failover   
  
<img width="664" alt="image" src="https://user-images.githubusercontent.com/50267433/159523079-ab51d1dc-059a-4794-92a4-223a27013319.png">

* Zookeeper 등의 코디네이터가 알아서 업데이트.(프라이머리와 세컨더리가 누구인지 데이터 저장)     
* 동일한 방식으로 관리가 가능하다는 장점이 있지만 다른 기능이 필요할 경우 직접 구현해야한다. 

## VIP 기반 
* 가상 주소 할당 방식    
* API 서버는 특정 주소(10.0.1.1)로만 접속하도록 함.
* 살아있는 다른 레다스 서버애 가상 주소 할당 해줌   

## DNS 기반 
* VIP와 동일, 단 DNS로 하는 방식이다.   

**VIP/DNS정리**    
* 클라이언트에 추가적인 구현이 필요하다.  
* VIP 기반은 외부로 서비스를 제공해야하는 서비스 업자에 유리하다.(예를 들어 클라우드 업체)    
* DNS 기반은 DNS cache TTL을 관리해야한다.   
    * 사용하는 언어별 DNS 캐싱 정책을 잘 알아야한다.   
    * 툴에 따라서 한번 가죠온 DNS 정보를 다시 호출하지 않는 경우도 존재한다.  
